{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49beb51-0148-4a6a-a8b7-0430bea7a3ac",
   "metadata": {
    "id": "b49beb51-0148-4a6a-a8b7-0430bea7a3ac"
   },
   "source": [
    "![alt text](header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f751d-6b6c-4fdf-90f0-1b861859b9c6",
   "metadata": {
    "id": "367f751d-6b6c-4fdf-90f0-1b861859b9c6"
   },
   "source": [
    "#  Descripci贸n del proyecto"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a766e321-48f1-49da-9efa-c21dae155fd0",
   "metadata": {
    "id": "a766e321-48f1-49da-9efa-c21dae155fd0"
   },
   "source": [
    "La empresa Pontia Bank S.L. necesita desarrollar un sistema de detecci贸n de transacciones fraudulentas.\n",
    "\n",
    "Esta compa帽铆a, tramita miles de transacciones diarias de todos sus clientes entre las cuales se quiere diferenciar entre las que son fraudulentas de las que no lo son. Para ello, se han extra铆do las transacciones realizadas en los 煤ltimos 30 d铆as (m谩s de 6 millones) e identificado (manualmente) aquellas que son fraudulentas.\n",
    "\n",
    "Sin embargo, resulta muy costoso e ineficiente necesitar una revisi贸n manual de la transacci贸n para su validaci贸n, por lo que se quiere automatizar esta tarea.\n",
    "\n",
    "La empresa carece de un sistema adecuado para almacenar y gestionar sus datos de las transacciones, por lo que no solo necesita ser capaz de identificar el fraude, sino que es necesario llevar a cabo una transformaci贸n digital completa alrededor de estos datos: empezando por su almacenamiento, pasando por su procesamiento y finalizando con la generaci贸n de resultados y c谩lculo de KPIs 煤tiles para el negocio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e94a1f-1934-4b78-b4cd-e593b31344d9",
   "metadata": {
    "id": "03e94a1f-1934-4b78-b4cd-e593b31344d9"
   },
   "source": [
    "#  Importaci贸n de librer铆as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca3e7bb-8156-4565-9118-3a8589884c0f",
   "metadata": {
    "id": "0ca3e7bb-8156-4565-9118-3a8589884c0f"
   },
   "outputs": [],
   "source": [
    "# Librer铆as para procesamiento de datos\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta, date\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9c8e3",
   "metadata": {},
   "source": [
    "<!-- \n",
    "  Paleta:\n",
    "  #10002b\n",
    "  #240046\n",
    "  #3c096c\n",
    "  #5a189a\n",
    "  #7b2cbf\n",
    "  #9d4edd\n",
    "  #c77dff\n",
    "  #e0aaff\n",
    "-->\n",
    "\n",
    "<div style=\"max-width: 500px; \n",
    "            margin: 1rem auto; \n",
    "            background: linear-gradient(to bottom right, #10002b, #240046);\n",
    "            color: #e0aaff; \n",
    "            border-radius: 5px; \n",
    "            padding: 1.5rem; \n",
    "            text-align: center;\">\n",
    "\n",
    "  <h2 style=\"margin-top: 0; color: #c77dff;\">Mensaje Importante</h2>\n",
    "  \n",
    "  <p style=\"font-size: 1rem; line-height: 1.4;\">\n",
    "    Se recomienda reiniciar el kernel de Python tras la finalizaci贸n de la conversi贸n a CSV de cada archivo.\n",
    "  </p>\n",
    "  \n",
    "  <a href=\"https://docs.digitalocean.com/products/paperspace/notebooks/how-to/restart-kernels/#:~:text=Restarting%20a%20Kernel&text=You%20can%20restart%20a%20single,file%20in%20the%20file%20manager.\"\n",
    "     style=\"display: inline-block; \n",
    "            margin-top: 1rem; \n",
    "            padding: 0.5rem 1rem; \n",
    "            background-color: #7b2cbf; \n",
    "            border: 2px solid #9d4edd; \n",
    "            color: #fff; \n",
    "            text-decoration: none; \n",
    "            border-radius: 4px;\n",
    "            font-weight: bold;\">\n",
    "    M谩s informaci贸n\n",
    "  </a>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d6fbc-65d2-4d96-9f58-aa2f826c178c",
   "metadata": {
    "id": "3d1d6fbc-65d2-4d96-9f58-aa2f826c178c"
   },
   "source": [
    "# 叼 Carga y tratamiento de archivos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f20898fe",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "路 Objetivo de esta secci贸n:\n",
    "\n",
    "    - Familiarizarse con la estructura y contenidos de los archivos en formato JSON.\n",
    "\n",
    "路 Tareas:\n",
    "\n",
    "    - Leer los archivos JSON en pandas y crear dataframes para su posterior manipulaci贸n.\n",
    "    - Realizar la carga de los archivos en formato JSON para su posterior conversi贸n a CSV\n",
    "    - Inspeccionar el n煤mero de registros correspondiente a cada campo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207938e7-b2b5-4674-87b4-1a508b3b5511",
   "metadata": {
    "id": "207938e7-b2b5-4674-87b4-1a508b3b5511"
   },
   "source": [
    "### Exploraci贸n de alarma_fraude.json"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e768ca2-02db-4228-9476-efed9ecbb831",
   "metadata": {
    "id": "2e768ca2-02db-4228-9476-efed9ecbb831",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "路 Descripci贸n de la informaci贸n contenida en este campo:\n",
    "    - alarma_fraude: los sistemas actuales de la empresa pretenden controlar las transferencias masivas de una cuenta a otra y se帽ala los intentos ilegales.\n",
    "    Un intento ilegal en este conjunto de datos es un intento de transferir m谩s de 200.000 en una sola transacci贸n.\n",
    "    Este campo indica si ha saltado esta alarma de los sistemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd83a7-f49b-428b-9979-de2d2904a04a",
   "metadata": {
    "id": "64dd83a7-f49b-428b-9979-de2d2904a04a",
    "outputId": "5e729f71-2ba0-483b-b2ab-469a684d287b"
   },
   "outputs": [],
   "source": [
    "# Ruta de los datos\n",
    "file_path = \"./datos/alarma_fraude.json\"\n",
    "\n",
    "# Cargar los datos JSON\n",
    "df_alarma_fraude = pd.read_json(file_path)\n",
    "\n",
    "# Imprimir los datos cargados\n",
    "print(\"Archivo cargado correctamente:\")\n",
    "display(df_alarma_fraude)\n",
    "\n",
    "# La estructura del archivo es la siguiente: (como ejemplo, un registro)\n",
    "# {\n",
    "#     \"2736446\": {\n",
    "#         \"t_id\": 2736446,\n",
    "#         \"mensaje_alarma\": \"Detectado_fraude\"\n",
    "#     }\n",
    "# }\n",
    "# Donde:\n",
    "# - \"2736446\" es una clave en el diccionario principal.\n",
    "# - El valor asociado es otro diccionario con:\n",
    "#     - \"t_id\": 2736446\n",
    "#     - \"mensaje_alarma\": \"Detectado_fraude\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c9b8d-cd1e-45c3-bac4-140d158b1877",
   "metadata": {
    "id": "416c9b8d-cd1e-45c3-bac4-140d158b1877",
    "outputId": "6d6e6f7b-95d5-41d4-d0b0-3cb65ca6589a"
   },
   "outputs": [],
   "source": [
    "df_alarma_fraude = pd.json_normalize(df_alarma_fraude)\n",
    "\n",
    "print(df_alarma_fraude)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f110d287-b086-40c3-9681-7e6c5cd58c06",
   "metadata": {
    "id": "f110d287-b086-40c3-9681-7e6c5cd58c06"
   },
   "source": [
    "Problema: al usar json.normalize(), esta funci贸n espera una lista de diccionarios o un diccionario con una clave espec铆fica que contiene los registros. Cuando lo usamos en este ejemplo, Pandas no sabe c贸mo interpretar las claves externas (\"2736446\") como parte del registro y nos devuelve un dataframe vac铆o, ya que no encuentra datos con ese formato para normalizar.\n",
    "\n",
    "Para corregir esto, necesitamos reestructurar los datos del JSON a una lista de diccionarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e84699-9b7d-4805-b45a-74b319e88445",
   "metadata": {
    "id": "d4e84699-9b7d-4805-b45a-74b319e88445",
    "outputId": "46ea2164-bb10-4b86-c2a4-a27f0f0d5bd6"
   },
   "outputs": [],
   "source": [
    "# Leemos los datos del JSON con \"with open\" antes de trabajar con dataframe y los asignamos a la variable datos:\n",
    "\n",
    "with open(\"./datos/alarma_fraude.json\", mode='r') as f:\n",
    "    datos_alarma_fraude = json.load(f)\n",
    "\n",
    "datos_alarma_fraude # Vemos la estructura de datos mencionada anteriormente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2a9abb-f765-4d8d-a679-a2166175653a",
   "metadata": {
    "id": "9e2a9abb-f765-4d8d-a679-a2166175653a"
   },
   "outputs": [],
   "source": [
    "# Creaci贸n del bucle para crear la lista de diccionarios:\n",
    "registros = []\n",
    "\n",
    "for clave, valor in datos_alarma_fraude.items():\n",
    "    registro = {'id':clave}\n",
    "    registro.update(valor)\n",
    "    registros.append(registro)\n",
    "\n",
    "# Creaci贸n del DataFrame a partir de la lista de registros:\n",
    "\n",
    "df_alarma_fraude = pd.DataFrame(registros)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "084cbccf-2893-45d4-89a6-1a79e3fe4db2",
   "metadata": {
    "id": "084cbccf-2893-45d4-89a6-1a79e3fe4db2"
   },
   "source": [
    "Analizamos el dataframe creado usando .head() para explorar los datos del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd9257-d241-4892-ad31-418c152d690b",
   "metadata": {
    "id": "cbcd9257-d241-4892-ad31-418c152d690b",
    "outputId": "7b15bea6-b08c-4895-fc00-2e468430ff0a"
   },
   "outputs": [],
   "source": [
    "display(df_alarma_fraude.head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7e530f-3344-4c24-ba92-a0f81accf35f",
   "metadata": {
    "id": "cf7e530f-3344-4c24-ba92-a0f81accf35f"
   },
   "source": [
    "Como parece que las columnas 'id' y 't_id' contienen el mismo dato, tiene sentido eliminar informaci贸n redundante. No obstante, antes de eliminar columnas del DataFrame, vamos a verificar si los valores de ambas columnas son exactamente iguales. De ser as铆, proceder铆amos a eliminar la columna 'id', ya que la columna 't_id' se utiliza en otros archivos JSON del proyecto.\n",
    "\n",
    "Importante: la columna 'id' proviene de las claves del diccionario JSON, por lo que, los datos ser谩n de tipo string, mientras que, los datos de la columna 't_id' son de tipo entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8d869-b430-47d3-bd3b-d3fc74936db3",
   "metadata": {
    "id": "f7a8d869-b430-47d3-bd3b-d3fc74936db3",
    "outputId": "c7c8fff4-fb7a-4302-a9f8-bcda8949c518"
   },
   "outputs": [],
   "source": [
    "# Realizamos la conversi贸n del tipo de datos:\n",
    "\n",
    "df_alarma_fraude['id'] = df_alarma_fraude['id'].astype(int)\n",
    "\n",
    "# Comparamos ambas columnas:\n",
    "\n",
    "son_iguales = (df_alarma_fraude['id'] == df_alarma_fraude['t_id']).all()\n",
    "\n",
    "print(f\"Los datos de la columna 'id' y 't_id' son iguales: {son_iguales}.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd370ea0-fe11-4449-9d91-ab6934d35817",
   "metadata": {
    "id": "dd370ea0-fe11-4449-9d91-ab6934d35817"
   },
   "source": [
    "Como los datos son iguales, eliminamos la columna id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592c75d-e692-4adb-90f8-3d7c5f704501",
   "metadata": {
    "id": "f592c75d-e692-4adb-90f8-3d7c5f704501"
   },
   "outputs": [],
   "source": [
    "df_alarma_fraude.drop(columns='id', inplace=True)\n",
    "\n",
    "df_alarma_fraude.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e92382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_alarma_fraude.shape[0]} filas y {df_alarma_fraude.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_alarma_fraude.dtypes}\\n\")\n",
    "\n",
    "df_alarma_fraude['mensaje_alarma'] = df_alarma_fraude['mensaje_alarma'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUS ------\\n\")\n",
    "print(f\"{df_alarma_fraude.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492d0c5-7b32-4397-abb5-993f12bb7761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creaci贸n del CSV\n",
    "\n",
    "file_path = \"./datos/alarma_fraude.json\"\n",
    "\n",
    "# Guardar el DataFrame como un archivo CSV\n",
    "csv_path = \"./datos/alarma_fraude.csv\"\n",
    "df_alarma_fraude.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"El DataFrame ha sido guardado correctamente en {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1a0c7-288f-4842-bb0d-5ac6c0b03378",
   "metadata": {
    "id": "11e1a0c7-288f-4842-bb0d-5ac6c0b03378"
   },
   "source": [
    "### Exploraci贸n de balances.json"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa5c5c8",
   "metadata": {},
   "source": [
    "路 Descripci贸n de la informaci贸n contenida en este campo:\n",
    "    - balaces: balance previo y posterior del cliente tras la transacci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd03141-ea24-41c8-8a7d-497a4e365e30",
   "metadata": {
    "id": "7fd03141-ea24-41c8-8a7d-497a4e365e30",
    "outputId": "74d6900a-91a4-4ad5-a0df-3eef4efa0c19"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    file_path = \"./datos/balances.json\"\n",
    "\n",
    "    # Intentar cargar el archivo JSON\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        df_balances = json.load(file)\n",
    "    print(\"Fichero JSON cargado\")\n",
    "\n",
    "    # Verificamos el tipo de datos cargados\n",
    "    print(f\"Tipo de datos cargados: {type(df_balances)}\")\n",
    "\n",
    "    # Si es un diccionario\n",
    "    if isinstance(df_balances, dict):\n",
    "        print(\"Estructura del diccionario:\")\n",
    "        print(f\"Claves del diccionario: {list(df_balances.keys())[:5]}\")  # Mostramos las primeras 5 claves\n",
    "\n",
    "        # Verificamos una de las claves y su estructura\n",
    "        sample_key = list(df_balances.keys())[0]  # Tomamos la primera clave como ejemplo\n",
    "        record = df_balances[sample_key]\n",
    "        print(f\"Estructura del primer registro de la clave '{sample_key}':\", record)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurri贸 un error inesperado: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95f14b07-f1eb-4300-825e-eeaacf140c2f",
   "metadata": {
    "id": "95f14b07-f1eb-4300-825e-eeaacf140c2f",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Cargamos el JSON que esta compuesto por listas de diccionario.\n",
    "\n",
    "Cada diccionario tiene 3 valores t_id, balance_prev y balance_post,\n",
    "pero hay registros que para una misma clave tienen una lista de unos 15 diccionarios, por eso no los puede leer bien directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820b000",
   "metadata": {
    "id": "f820b000",
    "outputId": "530fea86-ffa3-421a-f4c3-ab56b6db897a"
   },
   "outputs": [],
   "source": [
    " # Crear la lista para almacenar todos los registros\n",
    "all_records = []\n",
    "\n",
    "# Recorremos todas las claves y sus valores (listas de diccionarios)\n",
    "for key, value in df_balances.items():\n",
    "    # Verifica si el valor es una lista de registros\n",
    "    if isinstance(value, list):\n",
    "        for record in value:\n",
    "            record['key'] = key  # A帽ade la clave como columna adicional\n",
    "            all_records.append(record)\n",
    "    else:\n",
    "        print(f\"Advertencia: El valor asociado a la clave {key} no es una lista\")\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_balances = pd.DataFrame(all_records)\n",
    "print(\"DataFrame creado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d59828",
   "metadata": {
    "id": "06d59828",
    "outputId": "57801f9b-51b1-4f3f-fece-481f7874383a"
   },
   "outputs": [],
   "source": [
    "# Mostrar informaci贸n del DataFrame\n",
    "print(\"Primeros 20 registros del DataFrame:\")\n",
    "display(df_balances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_balances.shape[0]} filas y {df_balances.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d48065a",
   "metadata": {
    "id": "1d48065a",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "El data frame tiene las encabezados\n",
    "\n",
    "- t-id (transaction ID)\n",
    "- balance_prev (saldo anterior)\n",
    "- balance_post (saldo despu茅s)\n",
    "- key (id del cliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e396f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_balances.dtypes}\\n\")\n",
    "\n",
    "df_balances['key'] = df_balances['key'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUS ------\\n\")\n",
    "print(f\"{df_balances.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209d8c9-df7f-4b92-8a4a-e9ec329dc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creaci贸n del CSV\n",
    "\n",
    "try:\n",
    "    # Guardar el DataFrame en un archivo CSV\n",
    "    csv_path = \"./datos/balances.csv\"\n",
    "    df_balances.to_csv(csv_path, index=False)\n",
    "    print(f\"El DataFrame ha sido guardado correctamente en {csv_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurri贸 un error inesperado: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc3c07-902c-4b48-b141-bf5ac7c86b44",
   "metadata": {
    "id": "44fc3c07-902c-4b48-b141-bf5ac7c86b44"
   },
   "source": [
    "### Exploraci贸n de es_fraude.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219b718",
   "metadata": {
    "id": "b219b718",
    "outputId": "ed65e82c-8381-4406-80fc-984cb08f9f94"
   },
   "outputs": [],
   "source": [
    "# Ruta actualizada al archivo JSON\n",
    "file_path = \"./datos/es_fraude.json\"\n",
    "\n",
    "try:\n",
    "    # Intentar cargar el archivo JSON\n",
    "    with open(file_path, encoding='utf-8') as file:\n",
    "        df_es_fraude = json.load(file)\n",
    "    print(\"Fichero JSON cargado\")\n",
    "\n",
    "    # Verificamos el tipo de datos cargados\n",
    "    print(f\"Tipo de datos cargados: {type(df_es_fraude)}\")\n",
    "\n",
    "    # Si es un diccionario\n",
    "    if isinstance(df_es_fraude, dict):\n",
    "        print(\"Estructura del diccionario:\")\n",
    "        print(f\"Claves del diccionario: {list(df_es_fraude.keys())[:5]}\")  # Mostramos las primeras 5 claves\n",
    "\n",
    "        # Verificamos una de las claves y su estructura\n",
    "        sample_key = list(df_es_fraude.keys())[0]  # Tomamos la primera clave como ejemplo\n",
    "        record = df_es_fraude[sample_key]\n",
    "        print(f\"Estructura del primer registro de la clave '{sample_key}':\", record)\n",
    "\n",
    "    else:\n",
    "        print(\"El archivo JSON no es un diccionario. Es de tipo:\", type(df_es_fraude))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"El archivo {file_path} no se encuentra. Verifique la ruta.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error al decodificar el archivo JSON. Verifique su formato.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurri贸 un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafd1dd",
   "metadata": {
    "id": "3fafd1dd",
    "outputId": "11a937a1-a7b8-4761-f8d1-4166f824b252"
   },
   "outputs": [],
   "source": [
    "# Convertir el archivo a DataFrame y renombrar columnas\n",
    "df_es_fraude = pd.DataFrame(list(df_es_fraude.items()), columns=['fraude_id', 'es_fraude'])\n",
    "\n",
    "\n",
    "print(f'Este archivo contiene {df_es_fraude.shape[0]} filas y {df_es_fraude.shape[1]} columnas.')\n",
    "\n",
    "# Mostramos el dataframe df_es_fraude\n",
    "display(df_es_fraude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_es_fraude.dtypes}\\n\")\n",
    "\n",
    "df_es_fraude['fraude_id'] = df_es_fraude['fraude_id'].astype(int)\n",
    "df_es_fraude['es_fraude'] = df_es_fraude['es_fraude'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUS ------\\n\")\n",
    "print(f\"{df_es_fraude.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el valor True/False por 1 y 0\n",
    "df_es_fraude['es_fraude'] = np.where(df_es_fraude['es_fraude'] == 'False', 0, 1)\n",
    "\n",
    "display(df_es_fraude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84884590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_fraude.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9269fd7f-bf35-4ad5-8081-2a49e3869414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creaci贸n del CSV\n",
    "\n",
    "# Guardar el DataFrame como un archivo CSV\n",
    "csv_path = './datos/es_fraude.csv'\n",
    "df_es_fraude.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"El DataFrame ha sido guardado correctamente en {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f07b05-4ecc-490e-b769-32d92520c297",
   "metadata": {
    "id": "08f07b05-4ecc-490e-b769-32d92520c297"
   },
   "source": [
    "### Exploraci贸n de cuantia.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f647916-feaa-4ea3-bdee-7d03fc6ce73b",
   "metadata": {
    "id": "3f647916-feaa-4ea3-bdee-7d03fc6ce73b"
   },
   "outputs": [],
   "source": [
    "# Cargamos el archivo como JSON\n",
    "with open('./datos/cuantia.json') as f:\n",
    "    cuantia_json = json.load(f)\n",
    "\n",
    "# Inicializamos el diccionario de registros\n",
    "registros = {'t_id': [], 'cuantia': []}\n",
    "\n",
    "# Iteramos sobre las claves de cuant铆a_json\n",
    "for key in cuantia_json:\n",
    "    registros['t_id'].append(key)\n",
    "    registros['cuantia'].append(cuantia_json[key]['cuantia'])\n",
    "\n",
    "\n",
    "# Convertimos el JSON en un DataFrame\n",
    "df_cuantia = pd.DataFrame(registros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408d2ec-3907-4841-9989-db2de3b669ec",
   "metadata": {
    "id": "0408d2ec-3907-4841-9989-db2de3b669ec",
    "outputId": "41040854-aee7-482a-9919-818b7cdf96e1"
   },
   "outputs": [],
   "source": [
    "df_cuantia.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d9a40-0ca6-4438-b63f-d460437418cb",
   "metadata": {
    "id": "6e1d9a40-0ca6-4438-b63f-d460437418cb",
    "outputId": "b6ae4970-c7cf-448c-d623-c1c3d1c59a9a"
   },
   "outputs": [],
   "source": [
    "# Forma del DataFrame resultante\n",
    "\n",
    "print(f'Este archivo contiene {df_cuantia.shape[0]} filas y {df_cuantia.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b658db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES------\\n\")\n",
    "print(f\"{df_cuantia.dtypes}\\n\")\n",
    "\n",
    "df_cuantia['t_id'] = df_cuantia['t_id'].astype(int)\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUS------\\n\")\n",
    "print(f\"{df_cuantia.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117668dc-b939-479b-8cbf-fdfebf428874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creaci贸n del CSV\n",
    "\n",
    "print(\"Guardando el DataFrame como archivo CSV...\")\n",
    "df_cuantia.to_csv('./datos/cuantia.csv', index=False)\n",
    "print(\"El archivo CSV 'cuantia.csv' ha sido guardado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0715ac3-cab9-4455-81b2-02ff8a6f2622",
   "metadata": {
    "id": "a0715ac3-cab9-4455-81b2-02ff8a6f2622"
   },
   "source": [
    "### Exploraci贸n del archivo tiempo.json"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4569b776",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "路 tiempo: unidad de tiempo (n煤mero entero) que representa el momento en que se produce la transacci贸n contando el n煤mero de horas que han pasado\n",
    "desde las 07:00 del 1 de septiembre de 2022.\n",
    "\n",
    "Por ejemplo, si este campo indica un 8 significa que la transacci贸n se produjo a las 15:00 (07:00 m谩s 8 horas)\n",
    "del 1 de septiembre; mientras que si indica un 25 significa que se produjo a las 08:00 del 2 de septiembre de 2022 (25 horas despu茅s del momento de referencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c73829c2-71e6-4359-abc9-0d833d6383a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo JSON\n",
    "file_path = './datos/tiempo.json'\n",
    "archivo_json = os.path.join(file_path)\n",
    "\n",
    "# Abrimos y cargamos el archivo JSON\n",
    "with open(archivo_json, 'r', encoding='utf-8') as f:\n",
    "    datos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "59036952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo = pd.DataFrame(datos.keys(), columns=['hora_transaccion'])\n",
    "df_tiempo['t_id'] = list(datos.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9a7de2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo = df_tiempo.explode('t_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32959070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17161770",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_tiempo.shape[0]} filas y {df_tiempo.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce75826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversi贸n de la hora de la transacci贸n a tipo entero\n",
    "df_tiempo['hora_transaccion'] = df_tiempo['hora_transaccion'].astype(dtype='int')\n",
    "\n",
    "print(f\"{df_tiempo.dtypes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e408867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el tiempo en el que se realizaron las transacciones\n",
    "fecha_referencia = datetime(2022, 9, 1, 7, 0, 0)\n",
    "print(f'La fecha de referencia se da en este formato: {fecha_referencia}')\n",
    "\n",
    "# Se actualiza el campo hora_transacci贸n para sumar las horas dadas en n煤mero entero y la hora de referencia\n",
    "df_tiempo['hora_transaccion'] = fecha_referencia + pd.to_timedelta(df_tiempo['hora_transaccion'], unit='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15991632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_tiempo.dtypes}\\n\")\n",
    "\n",
    "df_tiempo['t_id'] = df_tiempo['t_id'].astype(int)\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUS ------\\n\")\n",
    "print(f\"{df_tiempo.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb2dc7-452a-464e-b66d-6dd4f891c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creaci贸n del CSV\n",
    "\n",
    "# Ruta para guardar el archivo CSV\n",
    "path_file = './datos/tiempo.csv'\n",
    "\n",
    "# Guardamos el DataFrame como archivo CSV\n",
    "df_tiempo.to_csv(path_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nEl archivo CSV ha sido guardado como 'tiempo.csv' en la misma carpeta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aMInqTAatLZ1",
   "metadata": {
    "id": "aMInqTAatLZ1"
   },
   "source": [
    "### Exploraci贸n de tipo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "RjWOnTfIr4_O",
   "metadata": {
    "id": "RjWOnTfIr4_O"
   },
   "outputs": [],
   "source": [
    "# Cargar el archivo JSON\n",
    "with open('./datos/tipo.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T1cgB5Xwr771",
   "metadata": {
    "id": "T1cgB5Xwr771"
   },
   "outputs": [],
   "source": [
    "# Normalizamos los datos JSON en un DataFrame\n",
    "\n",
    "df_tipo = pd.json_normalize(data)\n",
    "df_tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad05b53-3cdd-4604-90f4-5f9eb4e3e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paso Creamos una lista vac铆a para almacenar los datos de las transacciones\n",
    "transacciones = []\n",
    "\n",
    "# Definimos los tipos de transacciones que hay\n",
    "tipos = ['PAYMENT', 'TRANSFER', 'CASH_OUT', 'DEBIT', 'CASH_IN']\n",
    "\n",
    "# Iteramos en cada tipo de transacci贸n para combinar los t_id y tipos de transacci贸n en un DataFrame\n",
    "for tipo in tipos:\n",
    "    tipo_col = f'{tipo}.t_id'  # Construimos el nombre de la columna con los t_id\n",
    "    if tipo_col in df_tipo.columns:  # Verificamos si la columna 'tipo.t_id' existe en df\n",
    "        # Paso 6: Extendemos la lista de transacciones con los t_id y el tipo correspondiente\n",
    "        transacciones.extend([(t_id, tipo) for t_id in df_tipo[tipo_col].iloc[0]])  # Accedemos al primer (y 煤nico) elemento de la lista\n",
    "    else:\n",
    "        print(f\"Advertencia: la clave '{tipo}' no est谩 presente en el DataFrame.\")\n",
    "\n",
    "# Creamos el DataFrame con los resultados\n",
    "df_tipo = pd.DataFrame(transacciones, columns=['t_id', 'tipo'])\n",
    "\n",
    "# Verificar si el DataFrame tiene datos antes de mostrar una muestra\n",
    "if not df_tipo.empty:\n",
    "    # Mostrar una muestra de 5 filas del DataFrame\n",
    "    print(df_tipo.sample(5))\n",
    "else:\n",
    "    print(\"El DataFrame est谩 vac铆o, no se han encontrado transacciones.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_tipo.shape[0]} filas y {df_tipo.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9379a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_tipo.dtypes}\\n\")\n",
    "\n",
    "df_tipo['t_id'] = df_tipo['t_id'].astype(int)\n",
    "df_tipo['tipo'] = df_tipo['tipo'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUS ------\\n\")\n",
    "print(f\"{df_tipo.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add68e8-57c3-44b2-8858-a1ae430d3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el CSV\n",
    "\n",
    "# Ruta para guardar el archivo CSV\n",
    "path_file = './datos/tipo.csv'\n",
    "\n",
    "# Guardamos el DataFrame como archivo CSV\n",
    "df_tipo.to_csv(path_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nEl archivo CSV ha sido guardado como 'tipo.csv' en la misma carpeta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f48fff-382e-41f9-98df-96578e506129",
   "metadata": {},
   "source": [
    "### Exploraci贸n fichero clientes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d418e99e-d1f6-48f6-a04b-37d559eb014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo JSON\n",
    "file_path = './datos/clientes.json'\n",
    "\n",
    "# Cargar el archivo JSON\n",
    "with open(file_path, encoding='utf-8') as f:\n",
    "        data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "365bf227-d43d-48cf-a7ba-4b08fdac720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for key, value in data.items():\n",
    "  record = {\n",
    "    't_id':key,\n",
    "    'origen':value['origen'],\n",
    "    'destino':value['destino']\n",
    "  }\n",
    "  records.append(record)\n",
    "\n",
    "df_clientes = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db667c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_clientes.dtypes}\\n\")\n",
    "\n",
    "df_clientes['t_id'] = df_clientes['t_id'].astype(int)\n",
    "df_clientes['origen'] = df_clientes['origen'].astype('string')\n",
    "df_clientes['destino'] = df_clientes['destino'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUS ------\\n\")\n",
    "print(f\"{df_clientes.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03cd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_clientes.head(5))\n",
    "\n",
    "display(df_clientes.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfac824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_clientes.shape[0]} filas y {df_clientes.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c933a7b-f233-41c6-8dc5-68610ab6e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos archivo csv\n",
    "archivo_csv = \"./datos/clientes.csv\"\n",
    "df_clientes.to_csv(archivo_csv, index=False)  # index=False para no incluir el 铆ndice en el CSV\n",
    "print(f\"Archivo CSV creado exitosamente: {archivo_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae48a38",
   "metadata": {},
   "source": [
    "#  Uni贸n de datos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9817f505",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "En este apartado, se unen todas las tablas para generar un dataframe que contenga todos los campos que se generan en una transacci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1463c4c",
   "metadata": {},
   "source": [
    "## Uni贸n de es_fraude y alarma_fraude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bd8c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos ambos CSV\n",
    "df_es_fraude = pd.read_csv(\"./datos/es_fraude.csv\")\n",
    "df_alarma_fraude = pd.read_csv(\"./datos/alarma_fraude.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c809e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos la columna fraude_id de df_es_fraude para que se pueda unir tomando como referencia t_id\n",
    "df_es_fraude.rename(columns={'fraude_id':'t_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27676fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_fraude.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad17c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos ambos dataframes\n",
    "df_fraude = pd.merge(df_es_fraude, df_alarma_fraude, how='left', on='t_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ce56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraude.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "644c5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustituimos los NaN de mensaje_alarma\n",
    "df_fraude['mensaje_alarma'] = np.where(df_fraude['mensaje_alarma'] == 'Detectado_fraude', 'Detectado_fraude', 'No_detectado_fraude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d86027",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_fraude.sample(5))\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_fraude.dtypes}\\n\")\n",
    "\n",
    "df_fraude['mensaje_alarma'] = df_fraude['mensaje_alarma'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUS ------\\n\")\n",
    "print(f\"{df_fraude.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como un archivo CSV\n",
    "csv_path = \"./datos/fraude.csv\"\n",
    "df_fraude.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"El DataFrame ha sido guardado correctamente en {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685f558",
   "metadata": {},
   "source": [
    "## Creaci贸n de un DataFrame 煤nico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a816b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos todos los CSV\n",
    "balances = pd.read_csv(\"./datos/balances.csv\")\n",
    "clientes = pd.read_csv(\"./datos/clientes.csv\")\n",
    "cuantia = pd.read_csv(\"./datos/cuantia.csv\")\n",
    "fraude = pd.read_csv(\"./datos/fraude.csv\")\n",
    "tiempo = pd.read_csv(\"./datos/tiempo.csv\")\n",
    "tipo = pd.read_csv(\"./datos/tipo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3678ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_campos = []\n",
    "\n",
    "for i in balances.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en balances.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in clientes.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en clientes.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in cuantia.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en cuantia.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in fraude.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en fraude.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in tiempo.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en tiempo.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in tipo.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en tipo.csv son: {lista_campos}')\n",
    "lista_campos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0ceb9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos los dataframes\n",
    "dataframes = [clientes, cuantia, fraude, tiempo, tipo]\n",
    "\n",
    "def unir_por_t_id(left, right):\n",
    "    return pd.merge(left, right, on='t_id', how='left')\n",
    "\n",
    "df1 = reduce(unir_por_t_id, dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.dtypes)\n",
    "\n",
    "balances['key'] = balances['key'].astype('string')\n",
    "df1['destino'] = df1['destino'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a020f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.columns)\n",
    "print(balances.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "311cf8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "balances = balances.rename(columns={'key':'origen'})\n",
    "df2 = df1.merge(balances, how='inner', on=['origen', 't_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f6bd74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "balances = balances.rename(columns={'origen':'destino'})\n",
    "df = df2.merge(balances, how='inner', on=['destino', 't_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcffb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c84b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'El n煤mero de registros es de: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d346e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos las columnas correctamente\n",
    "df = df.rename(columns={'balance_prev_x':'balance_prev_or', 'balance_post_x':'balance_post_or', 'balance_prev_y':'balance_prev_des', 'balance_post_y':'balance_post_des'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b148785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregimos los tipo de datos\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df.dtypes}\\n\")\n",
    "\n",
    "df['origen'] = df['origen'].astype('string')\n",
    "df['destino'] = df['destino'].astype('string')\n",
    "df['es_fraude'] = df['es_fraude'].round().astype('Int64')\n",
    "df['mensaje_alarma'] = df['mensaje_alarma'].astype('string')\n",
    "df['hora_transaccion'] = df['hora_transaccion'].astype('datetime64[ns]')\n",
    "df['tipo'] = df['tipo'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUS ------\\n\")\n",
    "print(f\"{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b83a81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el dataframe a csv\n",
    "csv_path = \"./datos/df.csv\"\n",
    "df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "44fc3c07-902c-4b48-b141-bf5ac7c86b44"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
