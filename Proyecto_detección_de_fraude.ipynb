{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49beb51-0148-4a6a-a8b7-0430bea7a3ac",
   "metadata": {
    "id": "b49beb51-0148-4a6a-a8b7-0430bea7a3ac"
   },
   "source": [
    "![alt text](header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f751d-6b6c-4fdf-90f0-1b861859b9c6",
   "metadata": {
    "id": "367f751d-6b6c-4fdf-90f0-1b861859b9c6"
   },
   "source": [
    "# 🚀 Descripción del proyecto"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a766e321-48f1-49da-9efa-c21dae155fd0",
   "metadata": {
    "id": "a766e321-48f1-49da-9efa-c21dae155fd0"
   },
   "source": [
    "La empresa Pontia Bank S.L. necesita desarrollar un sistema de detección de transacciones fraudulentas.\n",
    "\n",
    "Esta compañía, tramita miles de transacciones diarias de todos sus clientes entre las cuales se quiere diferenciar entre las que son fraudulentas de las que no lo son. Para ello, se han extraído las transacciones realizadas en los últimos 30 días (más de 6 millones) e identificado (manualmente) aquellas que son fraudulentas.\n",
    "\n",
    "Sin embargo, resulta muy costoso e ineficiente necesitar una revisión manual de la transacción para su validación, por lo que se quiere automatizar esta tarea.\n",
    "\n",
    "La empresa carece de un sistema adecuado para almacenar y gestionar sus datos de las transacciones, por lo que no solo necesita ser capaz de identificar el fraude, sino que es necesario llevar a cabo una transformación digital completa alrededor de estos datos: empezando por su almacenamiento, pasando por su procesamiento y finalizando con la generación de resultados y cálculo de KPIs útiles para el negocio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e94a1f-1934-4b78-b4cd-e593b31344d9",
   "metadata": {
    "id": "03e94a1f-1934-4b78-b4cd-e593b31344d9"
   },
   "source": [
    "# 📚 Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca3e7bb-8156-4565-9118-3a8589884c0f",
   "metadata": {
    "id": "0ca3e7bb-8156-4565-9118-3a8589884c0f"
   },
   "outputs": [],
   "source": [
    "# Librerías para procesamiento de datos\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta, date\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9c8e3",
   "metadata": {},
   "source": [
    "<!-- \n",
    "  Paleta:\n",
    "  #10002b\n",
    "  #240046\n",
    "  #3c096c\n",
    "  #5a189a\n",
    "  #7b2cbf\n",
    "  #9d4edd\n",
    "  #c77dff\n",
    "  #e0aaff\n",
    "-->\n",
    "\n",
    "<div style=\"max-width: 500px; \n",
    "            margin: 1rem auto; \n",
    "            background: linear-gradient(to bottom right, #10002b, #240046);\n",
    "            color: #e0aaff; \n",
    "            border-radius: 5px; \n",
    "            padding: 1.5rem; \n",
    "            text-align: center;\">\n",
    "\n",
    "  <h2 style=\"margin-top: 0; color: #c77dff;\">Mensaje Importante</h2>\n",
    "  \n",
    "  <p style=\"font-size: 1rem; line-height: 1.4;\">\n",
    "    Se recomienda reiniciar el kernel de Python tras la finalización de la conversión a CSV de cada archivo.\n",
    "  </p>\n",
    "  \n",
    "  <a href=\"https://docs.digitalocean.com/products/paperspace/notebooks/how-to/restart-kernels/#:~:text=Restarting%20a%20Kernel&text=You%20can%20restart%20a%20single,file%20in%20the%20file%20manager.\"\n",
    "     style=\"display: inline-block; \n",
    "            margin-top: 1rem; \n",
    "            padding: 0.5rem 1rem; \n",
    "            background-color: #7b2cbf; \n",
    "            border: 2px solid #9d4edd; \n",
    "            color: #fff; \n",
    "            text-decoration: none; \n",
    "            border-radius: 4px;\n",
    "            font-weight: bold;\">\n",
    "    Más información\n",
    "  </a>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d6fbc-65d2-4d96-9f58-aa2f826c178c",
   "metadata": {
    "id": "3d1d6fbc-65d2-4d96-9f58-aa2f826c178c"
   },
   "source": [
    "# 🕵🏻 Carga y tratamiento de archivos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f20898fe",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "· Objetivo de esta sección:\n",
    "\n",
    "    - Familiarizarse con la estructura y contenidos de los archivos en formato JSON.\n",
    "\n",
    "· Tareas:\n",
    "\n",
    "    - Leer los archivos JSON en pandas y crear dataframes para su posterior manipulación.\n",
    "    - Realizar la carga de los archivos en formato JSON para su posterior conversión a CSV\n",
    "    - Inspeccionar el número de registros correspondiente a cada campo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207938e7-b2b5-4674-87b4-1a508b3b5511",
   "metadata": {
    "id": "207938e7-b2b5-4674-87b4-1a508b3b5511"
   },
   "source": [
    "### Exploración de alarma_fraude.json"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e768ca2-02db-4228-9476-efed9ecbb831",
   "metadata": {
    "id": "2e768ca2-02db-4228-9476-efed9ecbb831",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "· Descripción de la información contenida en este campo:\n",
    "    - alarma_fraude: los sistemas actuales de la empresa pretenden controlar las transferencias masivas de una cuenta a otra y señala los intentos ilegales.\n",
    "    Un intento ilegal en este conjunto de datos es un intento de transferir más de 200.000 en una sola transacción.\n",
    "    Este campo indica si ha saltado esta alarma de los sistemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd83a7-f49b-428b-9979-de2d2904a04a",
   "metadata": {
    "id": "64dd83a7-f49b-428b-9979-de2d2904a04a",
    "outputId": "5e729f71-2ba0-483b-b2ab-469a684d287b"
   },
   "outputs": [],
   "source": [
    "# Ruta de los datos\n",
    "file_path = \"./datos/alarma_fraude.json\"\n",
    "\n",
    "# Cargar los datos JSON\n",
    "df_alarma_fraude = pd.read_json(file_path)\n",
    "\n",
    "# Imprimir los datos cargados\n",
    "print(\"Archivo cargado correctamente:\")\n",
    "display(df_alarma_fraude)\n",
    "\n",
    "# La estructura del archivo es la siguiente: (como ejemplo, un registro)\n",
    "# {\n",
    "#     \"2736446\": {\n",
    "#         \"t_id\": 2736446,\n",
    "#         \"mensaje_alarma\": \"Detectado_fraude\"\n",
    "#     }\n",
    "# }\n",
    "# Donde:\n",
    "# - \"2736446\" es una clave en el diccionario principal.\n",
    "# - El valor asociado es otro diccionario con:\n",
    "#     - \"t_id\": 2736446\n",
    "#     - \"mensaje_alarma\": \"Detectado_fraude\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c9b8d-cd1e-45c3-bac4-140d158b1877",
   "metadata": {
    "id": "416c9b8d-cd1e-45c3-bac4-140d158b1877",
    "outputId": "6d6e6f7b-95d5-41d4-d0b0-3cb65ca6589a"
   },
   "outputs": [],
   "source": [
    "df_alarma_fraude = pd.json_normalize(df_alarma_fraude)\n",
    "\n",
    "print(df_alarma_fraude)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f110d287-b086-40c3-9681-7e6c5cd58c06",
   "metadata": {
    "id": "f110d287-b086-40c3-9681-7e6c5cd58c06"
   },
   "source": [
    "Problema: al usar json.normalize(), esta función espera una lista de diccionarios o un diccionario con una clave específica que contiene los registros. Cuando lo usamos en este ejemplo, Pandas no sabe cómo interpretar las claves externas (\"2736446\") como parte del registro y nos devuelve un dataframe vacío, ya que no encuentra datos con ese formato para normalizar.\n",
    "\n",
    "Para corregir esto, necesitamos reestructurar los datos del JSON a una lista de diccionarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e84699-9b7d-4805-b45a-74b319e88445",
   "metadata": {
    "id": "d4e84699-9b7d-4805-b45a-74b319e88445",
    "outputId": "46ea2164-bb10-4b86-c2a4-a27f0f0d5bd6"
   },
   "outputs": [],
   "source": [
    "# Leemos los datos del JSON con \"with open\" antes de trabajar con dataframe y los asignamos a la variable datos:\n",
    "\n",
    "with open(\"./datos/alarma_fraude.json\", mode='r') as f:\n",
    "    datos_alarma_fraude = json.load(f)\n",
    "\n",
    "datos_alarma_fraude # Vemos la estructura de datos mencionada anteriormente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2a9abb-f765-4d8d-a679-a2166175653a",
   "metadata": {
    "id": "9e2a9abb-f765-4d8d-a679-a2166175653a"
   },
   "outputs": [],
   "source": [
    "# Creación del bucle para crear la lista de diccionarios:\n",
    "registros = []\n",
    "\n",
    "for clave, valor in datos_alarma_fraude.items():\n",
    "    registro = {'id':clave}\n",
    "    registro.update(valor)\n",
    "    registros.append(registro)\n",
    "\n",
    "# Creación del DataFrame a partir de la lista de registros:\n",
    "\n",
    "df_alarma_fraude = pd.DataFrame(registros)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "084cbccf-2893-45d4-89a6-1a79e3fe4db2",
   "metadata": {
    "id": "084cbccf-2893-45d4-89a6-1a79e3fe4db2"
   },
   "source": [
    "Analizamos el dataframe creado usando .head() para explorar los datos del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd9257-d241-4892-ad31-418c152d690b",
   "metadata": {
    "id": "cbcd9257-d241-4892-ad31-418c152d690b",
    "outputId": "7b15bea6-b08c-4895-fc00-2e468430ff0a"
   },
   "outputs": [],
   "source": [
    "display(df_alarma_fraude.head())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf7e530f-3344-4c24-ba92-a0f81accf35f",
   "metadata": {
    "id": "cf7e530f-3344-4c24-ba92-a0f81accf35f"
   },
   "source": [
    "Como parece que las columnas 'id' y 't_id' contienen el mismo dato, tiene sentido eliminar información redundante. No obstante, antes de eliminar columnas del DataFrame, vamos a verificar si los valores de ambas columnas son exactamente iguales. De ser así, procederíamos a eliminar la columna 'id', ya que la columna 't_id' se utiliza en otros archivos JSON del proyecto.\n",
    "\n",
    "Importante: la columna 'id' proviene de las claves del diccionario JSON, por lo que, los datos serán de tipo string, mientras que, los datos de la columna 't_id' son de tipo entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8d869-b430-47d3-bd3b-d3fc74936db3",
   "metadata": {
    "id": "f7a8d869-b430-47d3-bd3b-d3fc74936db3",
    "outputId": "c7c8fff4-fb7a-4302-a9f8-bcda8949c518"
   },
   "outputs": [],
   "source": [
    "# Realizamos la conversión del tipo de datos:\n",
    "\n",
    "df_alarma_fraude['id'] = df_alarma_fraude['id'].astype(int)\n",
    "\n",
    "# Comparamos ambas columnas:\n",
    "\n",
    "son_iguales = (df_alarma_fraude['id'] == df_alarma_fraude['t_id']).all()\n",
    "\n",
    "print(f\"Los datos de la columna 'id' y 't_id' son iguales: {son_iguales}.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd370ea0-fe11-4449-9d91-ab6934d35817",
   "metadata": {
    "id": "dd370ea0-fe11-4449-9d91-ab6934d35817"
   },
   "source": [
    "Como los datos son iguales, eliminamos la columna id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592c75d-e692-4adb-90f8-3d7c5f704501",
   "metadata": {
    "id": "f592c75d-e692-4adb-90f8-3d7c5f704501"
   },
   "outputs": [],
   "source": [
    "df_alarma_fraude.drop(columns='id', inplace=True)\n",
    "\n",
    "df_alarma_fraude.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e92382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_alarma_fraude.shape[0]} filas y {df_alarma_fraude.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_alarma_fraude.dtypes}\\n\")\n",
    "\n",
    "df_alarma_fraude['mensaje_alarma'] = df_alarma_fraude['mensaje_alarma'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUÉS ------\\n\")\n",
    "print(f\"{df_alarma_fraude.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492d0c5-7b32-4397-abb5-993f12bb7761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación del CSV\n",
    "\n",
    "file_path = \"./datos/alarma_fraude.json\"\n",
    "\n",
    "# Guardar el DataFrame como un archivo CSV\n",
    "csv_path = \"./datos/alarma_fraude.csv\"\n",
    "df_alarma_fraude.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"El DataFrame ha sido guardado correctamente en {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1a0c7-288f-4842-bb0d-5ac6c0b03378",
   "metadata": {
    "id": "11e1a0c7-288f-4842-bb0d-5ac6c0b03378"
   },
   "source": [
    "### Exploración de balances.json"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fa5c5c8",
   "metadata": {},
   "source": [
    "· Descripción de la información contenida en este campo:\n",
    "    - balaces: balance previo y posterior del cliente tras la transacción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd03141-ea24-41c8-8a7d-497a4e365e30",
   "metadata": {
    "id": "7fd03141-ea24-41c8-8a7d-497a4e365e30",
    "outputId": "74d6900a-91a4-4ad5-a0df-3eef4efa0c19"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    file_path = \"./datos/balances.json\"\n",
    "\n",
    "    # Intentar cargar el archivo JSON\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        df_balances = json.load(file)\n",
    "    print(\"Fichero JSON cargado\")\n",
    "\n",
    "    # Verificamos el tipo de datos cargados\n",
    "    print(f\"Tipo de datos cargados: {type(df_balances)}\")\n",
    "\n",
    "    # Si es un diccionario\n",
    "    if isinstance(df_balances, dict):\n",
    "        print(\"Estructura del diccionario:\")\n",
    "        print(f\"Claves del diccionario: {list(df_balances.keys())[:5]}\")  # Mostramos las primeras 5 claves\n",
    "\n",
    "        # Verificamos una de las claves y su estructura\n",
    "        sample_key = list(df_balances.keys())[0]  # Tomamos la primera clave como ejemplo\n",
    "        record = df_balances[sample_key]\n",
    "        print(f\"Estructura del primer registro de la clave '{sample_key}':\", record)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95f14b07-f1eb-4300-825e-eeaacf140c2f",
   "metadata": {
    "id": "95f14b07-f1eb-4300-825e-eeaacf140c2f",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Cargamos el JSON que esta compuesto por listas de diccionario.\n",
    "\n",
    "Cada diccionario tiene 3 valores t_id, balance_prev y balance_post,\n",
    "pero hay registros que para una misma clave tienen una lista de unos 15 diccionarios, por eso no los puede leer bien directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820b000",
   "metadata": {
    "id": "f820b000",
    "outputId": "530fea86-ffa3-421a-f4c3-ab56b6db897a"
   },
   "outputs": [],
   "source": [
    " # Crear la lista para almacenar todos los registros\n",
    "all_records = []\n",
    "\n",
    "# Recorremos todas las claves y sus valores (listas de diccionarios)\n",
    "for key, value in df_balances.items():\n",
    "    # Verifica si el valor es una lista de registros\n",
    "    if isinstance(value, list):\n",
    "        for record in value:\n",
    "            record['key'] = key  # Añade la clave como columna adicional\n",
    "            all_records.append(record)\n",
    "    else:\n",
    "        print(f\"Advertencia: El valor asociado a la clave {key} no es una lista\")\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_balances = pd.DataFrame(all_records)\n",
    "print(\"DataFrame creado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d59828",
   "metadata": {
    "id": "06d59828",
    "outputId": "57801f9b-51b1-4f3f-fece-481f7874383a"
   },
   "outputs": [],
   "source": [
    "# Mostrar información del DataFrame\n",
    "print(\"Primeros 20 registros del DataFrame:\")\n",
    "display(df_balances.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_balances.shape[0]} filas y {df_balances.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d48065a",
   "metadata": {
    "id": "1d48065a",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "El data frame tiene las encabezados\n",
    "\n",
    "- t-id (transaction ID)\n",
    "- balance_prev (saldo anterior)\n",
    "- balance_post (saldo después)\n",
    "- key (id del cliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e396f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_balances.dtypes}\\n\")\n",
    "\n",
    "df_balances['key'] = df_balances['key'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUÉS ------\\n\")\n",
    "print(f\"{df_balances.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209d8c9-df7f-4b92-8a4a-e9ec329dc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creación del CSV\n",
    "\n",
    "try:\n",
    "    # Guardar el DataFrame en un archivo CSV\n",
    "    csv_path = \"./datos/balances.csv\"\n",
    "    df_balances.to_csv(csv_path, index=False)\n",
    "    print(f\"El DataFrame ha sido guardado correctamente en {csv_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc3c07-902c-4b48-b141-bf5ac7c86b44",
   "metadata": {
    "id": "44fc3c07-902c-4b48-b141-bf5ac7c86b44"
   },
   "source": [
    "### Exploración de es_fraude.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219b718",
   "metadata": {
    "id": "b219b718",
    "outputId": "ed65e82c-8381-4406-80fc-984cb08f9f94"
   },
   "outputs": [],
   "source": [
    "# Ruta actualizada al archivo JSON\n",
    "file_path = \"./datos/es_fraude.json\"\n",
    "\n",
    "try:\n",
    "    # Intentar cargar el archivo JSON\n",
    "    with open(file_path, encoding='utf-8') as file:\n",
    "        df_es_fraude = json.load(file)\n",
    "    print(\"Fichero JSON cargado\")\n",
    "\n",
    "    # Verificamos el tipo de datos cargados\n",
    "    print(f\"Tipo de datos cargados: {type(df_es_fraude)}\")\n",
    "\n",
    "    # Si es un diccionario\n",
    "    if isinstance(df_es_fraude, dict):\n",
    "        print(\"Estructura del diccionario:\")\n",
    "        print(f\"Claves del diccionario: {list(df_es_fraude.keys())[:5]}\")  # Mostramos las primeras 5 claves\n",
    "\n",
    "        # Verificamos una de las claves y su estructura\n",
    "        sample_key = list(df_es_fraude.keys())[0]  # Tomamos la primera clave como ejemplo\n",
    "        record = df_es_fraude[sample_key]\n",
    "        print(f\"Estructura del primer registro de la clave '{sample_key}':\", record)\n",
    "\n",
    "    else:\n",
    "        print(\"El archivo JSON no es un diccionario. Es de tipo:\", type(df_es_fraude))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"El archivo {file_path} no se encuentra. Verifique la ruta.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error al decodificar el archivo JSON. Verifique su formato.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafd1dd",
   "metadata": {
    "id": "3fafd1dd",
    "outputId": "11a937a1-a7b8-4761-f8d1-4166f824b252"
   },
   "outputs": [],
   "source": [
    "# Convertir el archivo a DataFrame y renombrar columnas\n",
    "df_es_fraude = pd.DataFrame(list(df_es_fraude.items()), columns=['fraude_id', 'es_fraude'])\n",
    "\n",
    "\n",
    "print(f'Este archivo contiene {df_es_fraude.shape[0]} filas y {df_es_fraude.shape[1]} columnas.')\n",
    "\n",
    "# Mostramos el dataframe df_es_fraude\n",
    "display(df_es_fraude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_es_fraude.dtypes}\\n\")\n",
    "\n",
    "df_es_fraude['fraude_id'] = df_es_fraude['fraude_id'].astype(int)\n",
    "df_es_fraude['es_fraude'] = df_es_fraude['es_fraude'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUÉS ------\\n\")\n",
    "print(f\"{df_es_fraude.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el valor True/False por 1 y 0\n",
    "df_es_fraude['es_fraude'] = np.where(df_es_fraude['es_fraude'] == 'False', 0, 1)\n",
    "\n",
    "display(df_es_fraude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84884590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_fraude.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9269fd7f-bf35-4ad5-8081-2a49e3869414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación del CSV\n",
    "\n",
    "# Guardar el DataFrame como un archivo CSV\n",
    "csv_path = './datos/es_fraude.csv'\n",
    "df_es_fraude.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"El DataFrame ha sido guardado correctamente en {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f07b05-4ecc-490e-b769-32d92520c297",
   "metadata": {
    "id": "08f07b05-4ecc-490e-b769-32d92520c297"
   },
   "source": [
    "### Exploración de cuantia.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f647916-feaa-4ea3-bdee-7d03fc6ce73b",
   "metadata": {
    "id": "3f647916-feaa-4ea3-bdee-7d03fc6ce73b"
   },
   "outputs": [],
   "source": [
    "# Cargamos el archivo como JSON\n",
    "with open('./datos/cuantia.json') as f:\n",
    "    cuantia_json = json.load(f)\n",
    "\n",
    "# Inicializamos el diccionario de registros\n",
    "registros = {'t_id': [], 'cuantia': []}\n",
    "\n",
    "# Iteramos sobre las claves de cuantía_json\n",
    "for key in cuantia_json:\n",
    "    registros['t_id'].append(key)\n",
    "    registros['cuantia'].append(cuantia_json[key]['cuantia'])\n",
    "\n",
    "\n",
    "# Convertimos el JSON en un DataFrame\n",
    "df_cuantia = pd.DataFrame(registros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408d2ec-3907-4841-9989-db2de3b669ec",
   "metadata": {
    "id": "0408d2ec-3907-4841-9989-db2de3b669ec",
    "outputId": "41040854-aee7-482a-9919-818b7cdf96e1"
   },
   "outputs": [],
   "source": [
    "df_cuantia.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d9a40-0ca6-4438-b63f-d460437418cb",
   "metadata": {
    "id": "6e1d9a40-0ca6-4438-b63f-d460437418cb",
    "outputId": "b6ae4970-c7cf-448c-d623-c1c3d1c59a9a"
   },
   "outputs": [],
   "source": [
    "# Forma del DataFrame resultante\n",
    "\n",
    "print(f'Este archivo contiene {df_cuantia.shape[0]} filas y {df_cuantia.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b658db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES------\\n\")\n",
    "print(f\"{df_cuantia.dtypes}\\n\")\n",
    "\n",
    "df_cuantia['t_id'] = df_cuantia['t_id'].astype(int)\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUÉS------\\n\")\n",
    "print(f\"{df_cuantia.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117668dc-b939-479b-8cbf-fdfebf428874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creación del CSV\n",
    "\n",
    "print(\"Guardando el DataFrame como archivo CSV...\")\n",
    "df_cuantia.to_csv('./datos/cuantia.csv', index=False)\n",
    "print(\"El archivo CSV 'cuantia.csv' ha sido guardado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0715ac3-cab9-4455-81b2-02ff8a6f2622",
   "metadata": {
    "id": "a0715ac3-cab9-4455-81b2-02ff8a6f2622"
   },
   "source": [
    "### Exploración del archivo tiempo.json"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4569b776",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "· tiempo: unidad de tiempo (número entero) que representa el momento en que se produce la transacción contando el número de horas que han pasado\n",
    "desde las 07:00 del 1 de septiembre de 2022.\n",
    "\n",
    "Por ejemplo, si este campo indica un 8 significa que la transacción se produjo a las 15:00 (07:00 más 8 horas)\n",
    "del 1 de septiembre; mientras que si indica un 25 significa que se produjo a las 08:00 del 2 de septiembre de 2022 (25 horas después del momento de referencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c73829c2-71e6-4359-abc9-0d833d6383a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo JSON\n",
    "file_path = './datos/tiempo.json'\n",
    "archivo_json = os.path.join(file_path)\n",
    "\n",
    "# Abrimos y cargamos el archivo JSON\n",
    "with open(archivo_json, 'r', encoding='utf-8') as f:\n",
    "    datos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "59036952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo = pd.DataFrame(datos.keys(), columns=['hora_transaccion'])\n",
    "df_tiempo['t_id'] = list(datos.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9a7de2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo = df_tiempo.explode('t_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32959070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17161770",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_tiempo.shape[0]} filas y {df_tiempo.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce75826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión de la hora de la transacción a tipo entero\n",
    "df_tiempo['hora_transaccion'] = df_tiempo['hora_transaccion'].astype(dtype='int')\n",
    "\n",
    "print(f\"{df_tiempo.dtypes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e408867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el tiempo en el que se realizaron las transacciones\n",
    "fecha_referencia = datetime(2022, 9, 1, 7, 0, 0)\n",
    "print(f'La fecha de referencia se da en este formato: {fecha_referencia}')\n",
    "\n",
    "# Se actualiza el campo hora_transacción para sumar las horas dadas en número entero y la hora de referencia\n",
    "df_tiempo['hora_transaccion'] = fecha_referencia + pd.to_timedelta(df_tiempo['hora_transaccion'], unit='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiempo.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15991632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_tiempo.dtypes}\\n\")\n",
    "\n",
    "df_tiempo['t_id'] = df_tiempo['t_id'].astype(int)\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUÉS ------\\n\")\n",
    "print(f\"{df_tiempo.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb2dc7-452a-464e-b66d-6dd4f891c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creación del CSV\n",
    "\n",
    "# Ruta para guardar el archivo CSV\n",
    "path_file = './datos/tiempo.csv'\n",
    "\n",
    "# Guardamos el DataFrame como archivo CSV\n",
    "df_tiempo.to_csv(path_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nEl archivo CSV ha sido guardado como 'tiempo.csv' en la misma carpeta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aMInqTAatLZ1",
   "metadata": {
    "id": "aMInqTAatLZ1"
   },
   "source": [
    "### Exploración de tipo.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "RjWOnTfIr4_O",
   "metadata": {
    "id": "RjWOnTfIr4_O"
   },
   "outputs": [],
   "source": [
    "# Cargar el archivo JSON\n",
    "with open('./datos/tipo.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T1cgB5Xwr771",
   "metadata": {
    "id": "T1cgB5Xwr771"
   },
   "outputs": [],
   "source": [
    "# Normalizamos los datos JSON en un DataFrame\n",
    "\n",
    "df_tipo = pd.json_normalize(data)\n",
    "df_tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad05b53-3cdd-4604-90f4-5f9eb4e3e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paso Creamos una lista vacía para almacenar los datos de las transacciones\n",
    "transacciones = []\n",
    "\n",
    "# Definimos los tipos de transacciones que hay\n",
    "tipos = ['PAYMENT', 'TRANSFER', 'CASH_OUT', 'DEBIT', 'CASH_IN']\n",
    "\n",
    "# Iteramos en cada tipo de transacción para combinar los t_id y tipos de transacción en un DataFrame\n",
    "for tipo in tipos:\n",
    "    tipo_col = f'{tipo}.t_id'  # Construimos el nombre de la columna con los t_id\n",
    "    if tipo_col in df_tipo.columns:  # Verificamos si la columna 'tipo.t_id' existe en df\n",
    "        # Paso 6: Extendemos la lista de transacciones con los t_id y el tipo correspondiente\n",
    "        transacciones.extend([(t_id, tipo) for t_id in df_tipo[tipo_col].iloc[0]])  # Accedemos al primer (y único) elemento de la lista\n",
    "    else:\n",
    "        print(f\"Advertencia: la clave '{tipo}' no está presente en el DataFrame.\")\n",
    "\n",
    "# Creamos el DataFrame con los resultados\n",
    "df_tipo = pd.DataFrame(transacciones, columns=['t_id', 'tipo'])\n",
    "\n",
    "# Verificar si el DataFrame tiene datos antes de mostrar una muestra\n",
    "if not df_tipo.empty:\n",
    "    # Mostrar una muestra de 5 filas del DataFrame\n",
    "    print(df_tipo.sample(5))\n",
    "else:\n",
    "    print(\"El DataFrame está vacío, no se han encontrado transacciones.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_tipo.shape[0]} filas y {df_tipo.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9379a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_tipo.dtypes}\\n\")\n",
    "\n",
    "df_tipo['t_id'] = df_tipo['t_id'].astype(int)\n",
    "df_tipo['tipo'] = df_tipo['tipo'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUÉS ------\\n\")\n",
    "print(f\"{df_tipo.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add68e8-57c3-44b2-8858-a1ae430d3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el CSV\n",
    "\n",
    "# Ruta para guardar el archivo CSV\n",
    "path_file = './datos/tipo.csv'\n",
    "\n",
    "# Guardamos el DataFrame como archivo CSV\n",
    "df_tipo.to_csv(path_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nEl archivo CSV ha sido guardado como 'tipo.csv' en la misma carpeta.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f48fff-382e-41f9-98df-96578e506129",
   "metadata": {},
   "source": [
    "### Exploración fichero clientes.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d418e99e-d1f6-48f6-a04b-37d559eb014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo JSON\n",
    "file_path = './datos/clientes.json'\n",
    "\n",
    "# Cargar el archivo JSON\n",
    "with open(file_path, encoding='utf-8') as f:\n",
    "        data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "365bf227-d43d-48cf-a7ba-4b08fdac720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for key, value in data.items():\n",
    "  record = {\n",
    "    't_id':key,\n",
    "    'origen':value['origen'],\n",
    "    'destino':value['destino']\n",
    "  }\n",
    "  records.append(record)\n",
    "\n",
    "df_clientes = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db667c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos el tipo de datos y corregimos\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_clientes.dtypes}\\n\")\n",
    "\n",
    "df_clientes['t_id'] = df_clientes['t_id'].astype(int)\n",
    "df_clientes['origen'] = df_clientes['origen'].astype('string')\n",
    "df_clientes['destino'] = df_clientes['destino'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUÉS ------\\n\")\n",
    "print(f\"{df_clientes.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03cd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_clientes.head(5))\n",
    "\n",
    "display(df_clientes.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfac824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Este archivo contiene {df_clientes.shape[0]} filas y {df_clientes.shape[1]} columnas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c933a7b-f233-41c6-8dc5-68610ab6e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos archivo csv\n",
    "archivo_csv = \"./datos/clientes.csv\"\n",
    "df_clientes.to_csv(archivo_csv, index=False)  # index=False para no incluir el índice en el CSV\n",
    "print(f\"Archivo CSV creado exitosamente: {archivo_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae48a38",
   "metadata": {},
   "source": [
    "# 📋 Unión de datos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9817f505",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "En este apartado, se unen todas las tablas para generar un dataframe que contenga todos los campos que se generan en una transacción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1463c4c",
   "metadata": {},
   "source": [
    "## Unión de es_fraude y alarma_fraude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8bd8c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos ambos CSV\n",
    "df_es_fraude = pd.read_csv(\"./datos/es_fraude.csv\")\n",
    "df_alarma_fraude = pd.read_csv(\"./datos/alarma_fraude.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c809e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos la columna fraude_id de df_es_fraude para que se pueda unir tomando como referencia t_id\n",
    "df_es_fraude.rename(columns={'fraude_id':'t_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27676fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_fraude.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad17c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos ambos dataframes\n",
    "df_fraude = pd.merge(df_es_fraude, df_alarma_fraude, how='left', on='t_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ce56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraude.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "644c5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustituimos los NaN de mensaje_alarma\n",
    "df_fraude['mensaje_alarma'] = np.where(df_fraude['mensaje_alarma'] == 'Detectado_fraude', 'Detectado_fraude', 'No_detectado_fraude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d86027",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_fraude.sample(5))\n",
    "\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df_fraude.dtypes}\\n\")\n",
    "\n",
    "df_fraude['mensaje_alarma'] = df_fraude['mensaje_alarma'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUÉS ------\\n\")\n",
    "print(f\"{df_fraude.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como un archivo CSV\n",
    "csv_path = \"./datos/fraude.csv\"\n",
    "df_fraude.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"El DataFrame ha sido guardado correctamente en {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685f558",
   "metadata": {},
   "source": [
    "## Creación de un DataFrame único"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a816b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos todos los CSV\n",
    "balances = pd.read_csv(\"./datos/balances.csv\")\n",
    "clientes = pd.read_csv(\"./datos/clientes.csv\")\n",
    "cuantia = pd.read_csv(\"./datos/cuantia.csv\")\n",
    "fraude = pd.read_csv(\"./datos/fraude.csv\")\n",
    "tiempo = pd.read_csv(\"./datos/tiempo.csv\")\n",
    "tipo = pd.read_csv(\"./datos/tipo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3678ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_campos = []\n",
    "\n",
    "for i in balances.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en balances.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in clientes.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en clientes.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in cuantia.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en cuantia.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in fraude.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en fraude.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in tiempo.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en tiempo.csv son: {lista_campos}')\n",
    "lista_campos = []\n",
    "\n",
    "for i in tipo.columns:\n",
    "    lista_campos.append(i)\n",
    "print(f'Las columnas que hay en tipo.csv son: {lista_campos}')\n",
    "lista_campos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0ceb9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos los dataframes\n",
    "dataframes = [clientes, cuantia, fraude, tiempo, tipo]\n",
    "\n",
    "def unir_por_t_id(left, right):\n",
    "    return pd.merge(left, right, on='t_id', how='left')\n",
    "\n",
    "df1 = reduce(unir_por_t_id, dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.dtypes)\n",
    "\n",
    "balances['key'] = balances['key'].astype('string')\n",
    "df1['destino'] = df1['destino'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a020f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.columns)\n",
    "print(balances.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "311cf8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "balances = balances.rename(columns={'key':'origen'})\n",
    "df2 = df1.merge(balances, how='inner', on=['origen', 't_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f6bd74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "balances = balances.rename(columns={'origen':'destino'})\n",
    "df = df2.merge(balances, how='inner', on=['destino', 't_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcffb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c84b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'El número de registros es de: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d346e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos las columnas correctamente\n",
    "df = df.rename(columns={'balance_prev_x':'balance_prev_or', 'balance_post_x':'balance_post_or', 'balance_prev_y':'balance_prev_des', 'balance_post_y':'balance_post_des'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b148785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corregimos los tipo de datos\n",
    "print(\"------ TIPO DE DATO ANTES ------\\n\")\n",
    "print(f\"{df.dtypes}\\n\")\n",
    "\n",
    "df['origen'] = df['origen'].astype('string')\n",
    "df['destino'] = df['destino'].astype('string')\n",
    "df['es_fraude'] = df['es_fraude'].round().astype('Int64')\n",
    "df['mensaje_alarma'] = df['mensaje_alarma'].astype('string')\n",
    "df['hora_transaccion'] = df['hora_transaccion'].astype('datetime64[ns]')\n",
    "df['tipo'] = df['tipo'].astype('string')\n",
    "\n",
    "print(\"------ TIPO DE DATO DESPUÉS ------\\n\")\n",
    "print(f\"{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b83a81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el dataframe a csv\n",
    "csv_path = \"./datos/df.csv\"\n",
    "df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "44fc3c07-902c-4b48-b141-bf5ac7c86b44"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
